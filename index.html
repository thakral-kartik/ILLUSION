<!DOCTYPE html>

<html lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    

<!-- Begin Jekyll SEO tag v2.7.1 -->
<title>ILLUSION: Integration of Life Like Unique Synthetic Identities and Objects from Neural Networks</title>
<meta name="generator" content="Jekyll v3.9.0">
<meta property="og:title" content="ILLUSION: Integration of Life Like Unique Synthetic Identities and Objects from Neural Networks">
<meta property="og:locale" content="en_US">
<link rel="canonical" href="https://bhashabluff.github.io/ILLUSION/">
<meta property="og:url" content="https://bhashabluff.github.io/ILLUSION//">
<meta name="twitter:card" content="summary">
<!-- End Jekyll SEO tag -->

    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#157878">
    <link rel="stylesheet" href="asset/diffgan-tts/style.css">
  </head>
  <body data-new-gr-c-s-check-loaded="14.1001.0" data-gr-ext-installed="">
    <section class="page-header">
    <!-- <h1 class="project-name">Demo PAGE</h1> -->
    <!-- <h2 class="project-tagline"></h2> -->
      
      
    </section>

    <section class="main-content">
      <h1 id=""><center> DiffGAN-TTS: High-Fidelity and Efficient Text-to-Speech with Denoising Diffusion GANs </center></h1>

<center> Anonymous Authors </center>
<!-- <center> <sup>2</sup> Tencent AI Lab </center> -->


<h2 id="abstract">Abstract</h2>
<p>
The recent surge in the spread of deepfakes and AI-generated content on social media platforms has led to a significant increase in media forgeries, 
    thereby intensifying the need for effective detection research. However, there is a conspicuous absence of a comprehensive dataset that encapsulates various 
    types of fake media across all three modalities: image, audio, and video. This study addresses this gap by introducing \textbf{ILLUSION} (\textbf{I}ntegration of \textbf{L}ife-\textbf{L}ike \textbf{U}nique \textbf{S}ynthetic \textbf{I}dentities and Objects from \textbf{N}eural Networks), 
    a large-scale, multi-modal deepfake dataset. This first-of-its-kind dataset is created using a variety of state-of-the-art generative models and includes face swaps, audio spoofs, audio-video synchronized and synthetically generated images, faces, audio, and videos. The dataset, balanced in terms of sex and 
    skin tone, comprises a total of 1,371,986 samples. The ILLUSION dataset is designed to facilitate the development of deepfake detection systems that are unified across all three modalities and robust against all 
    types of fake media. Furthermore, we benchmark the dataset with popular and state-of-the-art algorithms for images, audio, and videos, demonstrating its utility and effectiveness in the field of deepfake detection research.
</p>






</section>
</body></html>
